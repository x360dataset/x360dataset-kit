{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the needed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Face_Anomolyze.ipynb\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1TBtViihvgzkntviMBScLIQY3UQ3EoAB2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"# Run\"\"\"\n",
    "\n",
    "!ls  ~/.insightface/models/\n",
    "!gdown 1qXsQJ8ZT42_xSmWIYy85IcidpiZudOCB\n",
    "!unzip buffalo_l.zip\n",
    "\n",
    "\n",
    "!mkdir ~/.insightface\n",
    "!mkdir ~/.insightface/models/\n",
    "!cp -r buffalo_l  ~/.insightface/models/\n",
    "\n",
    "!pip install insightface==0.7.1\n",
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "output_path = \"./processed_video\"\n",
    "! mkdir output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If buggy please commented out the following IPython magic to ensure Python compatibility.\n",
    "# replace the writefile to your own face_analysis.py path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile /usr/local/lib/python3.10/dist-packages/insightface/app/face_analysis.py\n",
    "# \n",
    "# from __future__ import division\n",
    "# \n",
    "# import glob\n",
    "# import os.path as osp\n",
    "# \n",
    "# import numpy as np\n",
    "# import onnxruntime\n",
    "# from numpy.linalg import norm\n",
    "# \n",
    "# from ..model_zoo import model_zoo\n",
    "# from ..utils import DEFAULT_MP_NAME, ensure_available\n",
    "# from .common import Face\n",
    "# \n",
    "# __all__ = ['FaceAnalysis']\n",
    "# \n",
    "# class FaceAnalysis:\n",
    "#     def __init__(self, name=DEFAULT_MP_NAME, root='~/.insightface', allowed_modules=None, **kwargs):\n",
    "#         onnxruntime.set_default_logger_severity(3)\n",
    "#         self.models = {}\n",
    "#         self.model_dir = ensure_available('models', name, root=root)\n",
    "#         onnx_files = glob.glob(osp.join(self.model_dir, '*.onnx'))\n",
    "#         onnx_files = sorted(onnx_files)\n",
    "#         for onnx_file in onnx_files:\n",
    "#             model = model_zoo.get_model(onnx_file, **kwargs)\n",
    "#             if model is None:\n",
    "#                 print('model not recognized:', onnx_file)\n",
    "#             elif allowed_modules is not None and model.taskname not in allowed_modules:\n",
    "#                 print('model ignore:', onnx_file, model.taskname)\n",
    "#                 del model\n",
    "#             elif model.taskname not in self.models and (allowed_modules is None or model.taskname in allowed_modules):\n",
    "#                 print('find model:', onnx_file, model.taskname, model.input_shape, model.input_mean, model.input_std)\n",
    "#                 self.models[model.taskname] = model\n",
    "#             else:\n",
    "#                 print('duplicated model task type, ignore:', onnx_file, model.taskname)\n",
    "#                 del model\n",
    "#         assert 'detection' in self.models\n",
    "#         self.det_model = self.models['detection']\n",
    "# \n",
    "# \n",
    "#     def prepare(self, ctx_id, det_thresh=0.5, det_size=(640, 640)):\n",
    "#         self.det_thresh = det_thresh\n",
    "#         assert det_size is not None\n",
    "#         print('set det-size:', det_size)\n",
    "#         self.det_size = det_size\n",
    "#         for taskname, model in self.models.items():\n",
    "#             if taskname=='detection':\n",
    "#                 model.prepare(ctx_id, input_size=det_size, det_thresh=det_thresh)\n",
    "#             else:\n",
    "#                 model.prepare(ctx_id)\n",
    "# \n",
    "#     def get(self, img, max_num=0):\n",
    "#         bboxes, kpss = self.det_model.detect(img,\n",
    "#                                              max_num=max_num,\n",
    "#                                              metric='default')\n",
    "#         if bboxes.shape[0] == 0:\n",
    "#             return []\n",
    "#         ret = []\n",
    "#         for i in range(bboxes.shape[0]):\n",
    "#             bbox = bboxes[i, 0:4]\n",
    "#             det_score = bboxes[i, 4]\n",
    "#             kps = None\n",
    "#             if kpss is not None:\n",
    "#                 kps = kpss[i]\n",
    "#             face = Face(bbox=bbox, kps=kps, det_score=det_score)\n",
    "#             for taskname, model in self.models.items():\n",
    "#                 if taskname=='detection':\n",
    "#                     continue\n",
    "#                 model.get(img, face)\n",
    "#             ret.append(face)\n",
    "#         return ret\n",
    "# \n",
    "#     def draw_on(self, img, faces):\n",
    "#         import cv2\n",
    "#         dimg = img.copy()\n",
    "#         for i in range(len(faces)):\n",
    "#             face = faces[i]\n",
    "#             box = face.bbox.astype(np.int32)\n",
    "#             color = (0, 0, 255)\n",
    "#             cv2.rectangle(dimg, (box[0], box[1]), (box[2], box[3]), color, 2)\n",
    "#             if face.kps is not None:\n",
    "#                 kps = face.kps.astype(np.int32)\n",
    "#                 #print(landmark.shape)\n",
    "#                 for l in range(kps.shape[0]):\n",
    "#                     color = (0, 0, 255)\n",
    "#                     if l == 0 or l == 3:\n",
    "#                         color = (0, 255, 0)\n",
    "#                     cv2.circle(dimg, (kps[l][0], kps[l][1]), 1, color,\n",
    "#                                2)\n",
    "#             if face.gender is not None and face.age is not None:\n",
    "#                 cv2.putText(dimg,'%s,%d'%(face.sex,face.age), (box[0]-1, box[1]-4),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,255,0),1)\n",
    "# \n",
    "#         return dimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# !wget https://master.dl.sourceforge.net/project/insightface.mirror/v0.7/scrfd_person_2.5g.onnx?viasf=1\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import insightface\n",
    "\n",
    "import imp\n",
    "imp.reload(insightface)\n",
    "\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "\n",
    "# Method-1, use FaceAnalysis\n",
    "# detector = insightface.model_zoo.get_model('scrfd_person_2.5g.onnx', download=True)\n",
    "detector = FaceAnalysis(name=\"buffalo_l\") # enable detection model only\n",
    "detector.prepare(ctx_id=0,  det_thresh=0.4, det_size=(1280, 1280))\n",
    "\n",
    "def detect_person(img, detector):\n",
    "    bboxes, kpss = detector.detect(img, (680, 680))\n",
    "    bboxes = np.round(bboxes[:,:4]).astype(np.int)\n",
    "    kpss = np.round(kpss).astype(np.int)\n",
    "    kpss[:,:,0] = np.clip(kpss[:,:,0], 0, img.shape[1])\n",
    "    kpss[:,:,1] = np.clip(kpss[:,:,1], 0, img.shape[0])\n",
    "    vbboxes = bboxes.copy()\n",
    "    vbboxes[:,0] = kpss[:, 0, 0]\n",
    "    vbboxes[:,1] = kpss[:, 0, 1]\n",
    "    vbboxes[:,2] = kpss[:, 4, 0]\n",
    "    vbboxes[:,3] = kpss[:, 4, 1]\n",
    "    return bboxes, vbboxes\n",
    "\n",
    "def get_detector_bbox(img):\n",
    "  # bboxes, vbboxes = detect_person(img, detector)\n",
    "\n",
    "  faces = detector.get(img)\n",
    "  return faces\n",
    "\n",
    "\n",
    "def blur_img(img, face, frame):\n",
    "  bbox = face[\"bbox\"]\n",
    "  ksize = (50, 50)\n",
    "\n",
    "  y1 = np.maximum(round(bbox[0]), 0)\n",
    "  x1 = np.maximum(round(bbox[1]), 0)\n",
    "  y2 = np.maximum(round(bbox[2]), 0)\n",
    "  x2 = np.maximum(round(bbox[3]), 0)\n",
    "\n",
    "  print(f\"frame = {frame}, x1,x2,y1,y2\", x1,x2,y1,y2, img.shape)\n",
    "\n",
    "  # Using cv2.blur() method\n",
    "  img[x1:x2, y1:y2] = cv2.blur(img[x1:x2, y1:y2], ksize)\n",
    "\n",
    "  # Displaying the image\n",
    "  return img\n",
    "\n",
    "!mkdir /content/drive/MyDrive/saver_image_cvpr2024\n",
    "\n",
    "import cv2\n",
    "def cv_read_img(path):\n",
    "  return  cv2.imread(path, 1)\n",
    "\n",
    "import cv2, os\n",
    "\n",
    "\n",
    "def rotate(img, mode=1):\n",
    "# rotate(src, rotateCode[, dst]) ->\n",
    "  if mode == 1:\n",
    "    return cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "  elif mode == 2:\n",
    "    return cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "  else:\n",
    "    print(\"mode=\", mode)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def VideoProcess(video, mode=0):\n",
    "    bboxs = []\n",
    "    vid = cv2.VideoCapture(video)\n",
    "    filename = video.split(\"/\")[-1]\n",
    "    save_file = f'/content/drive/MyDrive/saver_image_cvpr2024/{filename}.avi'\n",
    "    if os.path.exists(save_file):\n",
    "      return\n",
    "\n",
    "    last_box = []\n",
    "    last2_box = []\n",
    "    last3_box = []\n",
    "\n",
    "    print(\"processing: \", filename)\n",
    "    if vid.isOpened():\n",
    "        number=0\n",
    "        while True:\n",
    "            ret, frame = vid.read()\n",
    "            if ret !=1:\n",
    "               break\n",
    "\n",
    "            if number == 0:\n",
    "                fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "                h, w, c= frame.shape\n",
    "                size = (w, h)\n",
    "                saver = cv2.VideoWriter(save_file,\n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),  fps, size)\n",
    "            if mode !=0:\n",
    "              frame = rotate(frame, mode)\n",
    "\n",
    "\n",
    "            faces = get_detector_bbox(frame)\n",
    "            bboxs.append(bboxs)\n",
    "            for face in faces:\n",
    "              frame = blur_img(frame, face, number)\n",
    "              # last_box =\n",
    "\n",
    "            for f in last_box:\n",
    "               frame = blur_img(frame, f, number)\n",
    "\n",
    "            for f in last2_box:\n",
    "               frame = blur_img(frame, f, number)\n",
    "\n",
    "            for f in last3_box:\n",
    "               frame = blur_img(frame, f, number)\n",
    "\n",
    "            last3_box = last2_box\n",
    "            last2_box = last_box\n",
    "            last_box = faces\n",
    "\n",
    "            if mode !=0:\n",
    "              frame = rotate(frame, 3 - mode)\n",
    "\n",
    "            saver.write(frame)\n",
    "            number+=1\n",
    "\n",
    "    else:\n",
    "        print('video reading failed!')\n",
    "\n",
    "    print(f\"save: {save_file} success\")\n",
    "    vid.release()\n",
    "    saver.release()\n",
    "    return bboxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for anomolyze video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# The mode is the rotation mode\n",
    "\n",
    "v = \"./media/media23.mp4\"\n",
    "VideoProcess(v, mode=1)\n",
    "\n",
    "# Or\n",
    "\n",
    "from glob import glob\n",
    "videos = glob(\"./media/*.mp4\")\n",
    "\n",
    "for v in videos:\n",
    "  VideoProcess(v)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
